# Data Analysis with Python

## Jupyter Notebook
Jupyter Notebook is an open-source web application that allows you to create and share documents containing live code, equations, visualizations, and narrative text. It supports various programming languages, including Python, R, Julia, and more. Jupyter Notebooks are widely used in data science, scientific research, and education.

## Pandas
Pandas is a powerful open-source data manipulation and analysis library for Python. It provides easy-to-use data structures and functions needed to work with structured data seamlessly. Pandas is built on top of the NumPy library, which is a powerful numerical computing library for Python. NumPy provides high-performance multidimensional array objects and functions to operate on these arrays. Pandas leverages NumPy arrays to store and manipulate data efficiently.

## Two Primary Data Structure
Pandas provides two primary data structures: DataFrame and Series. These data structures are fundamental to working with structured data in Pandas.

### 1. DataFrame:
A DataFrame is a two-dimensional, tabular data structure with labeled axes (rows and columns). It can be thought of as an in-memory representation of an Excel spreadsheet or a SQL table. Key features of a DataFrame include:

- **Tabular Structure:** Data is organized in a table with rows and columns.
- **Labeled Axes:** Both rows and columns have labels, allowing for easy referencing and manipulation.
- **Columnar Data:** Each column in a DataFrame can have a different data type.
- **Flexibility:** Supports various data types, including numeric, string, boolean, and more.
- **Alignment:** Operations are aligned on both rows and columns.


```python
 # Example of creating a DataFrame:

import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'San Francisco', 'Los Angeles']}

df = pd.DataFrame(data)
```

### 2. Series:

A Series is a one-dimensional labeled array capable of holding any data type. It can be thought of as a single column of a DataFrame. Key features of a Series include:

- **One-Dimensional:** Represents a single column or row of data.
- **Labeled Data:** Each element in a Series has a label (index).
- **Homogeneous Data:** All elements in a Series must have the same data type.
- **Similar to NumPy Arrays:** Series is similar to NumPy arrays but with axis labels.

Example of creating a Series:

```python
import pandas as pd

ages = pd.Series([25, 30, 35], name='Age')
```
## Columns and Index

**Columns**
Columns refer to the variables or fields present in a DataFrame. A DataFrame is a two-dimensional, tabular data structure where data is organized in rows and columns. Each column in a DataFrame is a Pandas Series, and the columns collectively define the structure of the dataset.

```python
import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'San Francisco', 'Los Angeles']}

df = pd.DataFrame(data)
name_column = df['Name']
```


**index**
The index in a Pandas DataFrame is a structure that provides labels for the rows. By default, when you create a DataFrame, Pandas assigns integer indices starting from 0. However, you can customize the index to be more meaningful or to better represent the nature of your data.



```python
 # Use below command for installing the pandas
pip install pandas 
 # Use below command for upgrading the pandas
pip install --upgarde pandas

 #Following code examples will use in jupyter notebook
 # First of all make a dictionary
dict = {
    "Name":["Jason", "Jackob", "John", "Owais"],
    "Age":[21, 23, 45, 26],
    "Salary":[2000, 3000, 4000, 4500],
    "City":["Tokyo", "Dhaka", "Delhi", "Karachi"]}
```

## Understanding Your Data: A Preliminary Analysis

Before diving into any analysis, it's crucial to gain a comprehensive understanding of your dataset. Key aspects to check include:

### Data Types
| Pandas Type           | Native Python Type        | Description                              |
|-----------------------|---------------------------|------------------------------------------|
| object                | string                    | alphanumeric characters                  |
| int64                 | int                       | numeric characters                      |
| float64               | float                     | numeric characters with decimal values   |
| Datetime64, Timedelta[ns] | N/A (datetime module in Python Standard Library) | time-related data               |

#### Why Check Data Types?
1. **Identify Potential Issues:** Uncover discrepancies between expected and actual data types.
2. **Ensure Compatibility:** Confirm alignment with Python methods for seamless analysis.

#### Checking Data Types in Pandas:
- Utilize `dataframe.dtypes` to inspect data types.
- Obtain a statistical summary with `dataframe.describe()`.
- For a comprehensive overview, use `df.describe(include="all")`.


## 1. Scientific Computing Libraries

### Pandas (Data Structures and Tools)
Pandas is a powerful library for data manipulation and analysis. It provides easy-to-use data structures, such as DataFrames, for efficient data organization and manipulation. Pandas is widely used for tasks like data cleaning, exploration, and transformation.

### Numpy (Arrays and Matrices)
Numpy is fundamental for numerical operations in Python. It introduces support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. This library is essential for scientific computing and data analysis.

### SciPy (Integrals, Solving Differential Equations, Optimization)
SciPy builds on Numpy and adds additional functionality for scientific and technical computing. It includes modules for integration, optimization, signal and image processing, and solving differential equations. SciPy complements Numpy, providing a comprehensive suite for scientific computing tasks.

## 2. Visualization Libraries

### Matplotlib (Graphs & Plots, Most Popular)
Matplotlib is a versatile plotting library for creating static, interactive, and animated visualizations in Python. It is widely used for generating various types of plots, charts, and graphs, making it an essential tool for data visualization.

### Seaborn (Plots: heat maps, time series, violin plots)
Seaborn is built on top of Matplotlib and specializes in statistical data visualization. It simplifies the creation of informative and attractive statistical graphics. Seaborn is particularly useful for visualizing complex relationships in data, including heat maps, time series, and violin plots.

## 3. Algorithm Libraries

### Scikit-learn (Machine Learning: Regression, Classification, and so on)
Scikit-learn is a robust machine learning library that provides simple and efficient tools for data mining and data analysis. It includes various algorithms for classification, regression, clustering, and dimensionality reduction, making it a go-to choice for machine learning tasks.

### Statsmodels (Explore Data, Estimate Statistical Models, and Perform Statistical Tests)
Statsmodels focuses on estimating and testing statistical models. It is particularly useful for exploring relationships in data, estimating parameters, and conducting hypothesis tests. Statsmodels complements Scikit-learn, offering capabilities specific to statistical modeling.

## Importing Data
Process of loading and reading data into python from various resources.
**Two Important Properties**
* **Format**: refers to the structure and organization of the data file. It specifies how the data is arranged and stored, such as CSV (Comma-Separated Values), Excel, JSON (JavaScript Object Notation), or others.
* **File Path**: A "file path" is the unique location address of a file within a computer's file system. It includes the directory or folder hierarchy and the file name. For example, on Windows, a file path might look like C:\Users\Username\Documents\Data\file.csv, where file.csv is the name of the file in the specified directory.

## Importing Data Sets
1. Read CSV data set: Read the CSV file containing a data set to a pandas data frame.
```pyhon
df = pd.read_csv(<CSV_path>, header = None) 
 # load without header 
df = pd.read_csv(<CSV_path>, header = 0) 
 # load using first row as header
```
2. Print first few entries: Print the first few entries (default 5) of the pandas data frame.
```python
df.head(n) #n=number of entries; default 5
```
3. Print last few entries: Print the last few entries (default 5) of the pandas data frame.
```python
df.tail(n) #n=number of entries; default 5
```
4. Assign header names: Assign appropriate header names to the data frame.
```python
df.columns = headers
```
5. Replace "?" with NaN: Replace the entries "?" with NaN entry from Numpy library.
```python
df = df.replace("?", np.nan)
```
6. Retrieve data types: Retrieve the data types of the data frame columns.
```python
df.dtypes
```
7. Retrieve statistical description: Retrieve the statistical description of the data set. Defaults use is for only numerical data types. Use include="all" to create summary for all variables.
```python
df.describe() #default use df.describe(include="all")
```
8. Retrieve data set summary: Retrieve the summary of the data set being used, from the data frame
```python
df.info()
```
9. Save data frame to CSV: Save the processed data frame to a CSV file with a specified path.
```python
df.to_csv(<output CSV path>)
```

```
 # Working Pandas using Jupyter Notebook
import pandas as pd
import numpy as np
import os
url = https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data
df = pd.read_csv(url, header=None)
df.head(5)
Headers = ["Symboling", "Normalized-Losses", "Make", "Fuel", "Aspiration", "Number-of-Doors", "Body-Style", "Driven-Wheels", "Engine-Locaiton", "Wheel-Base", "Length", "Width", "Height", "Curb-Weight", "Engine-Type", "Number-of-Cylinders", "Engine-Size", "Fuel-System", "Bore", "Stroke", "Compression-Ration","Horse-Poweer", "Peak-rpw", "City-mpg", "Highway-mpg", "Price"]
df.columns = Headers
df.head(5)
df.describe()
df.to_csv("Auto Data.csv")
```

